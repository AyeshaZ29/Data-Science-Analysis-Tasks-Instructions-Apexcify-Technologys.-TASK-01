# -*- coding: utf-8 -*-
"""TASK  1: Basic Descriptive Statistics on Dataset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IV4heUx4UPPnmwohQ6TvpgsXa6AHAHrS

#TASK 1: Basic Descriptive Statistics on Dataset
--------------------------------------------------
Objective:
- Load any small dataset (e.g., iris, tips, or Titanic from seaborn).
- Calculate descriptive statistics: mean, median, min, max, standard deviation.
Tools:
- Python, Pandas
Key Concepts:
- describe(), mean(), std(), min(), max()

Bonus:
- Identify any missing values using isnull().sum()

Step 1:
##Import Libraries & Load Dataset

###Pandas is a Python library used for:


Data analysis

Data manipulation

Handling CSV, Excel, SQL data
"""

import pandas as pd
df= pd.read_csv("/content/Iris (1).csv")

"""###Descriptive Statistics (describe)"""

print(df.describe())

"""##Individual Statistics

#Mean
"""

print("Mean:\n", df.mean(numeric_only=True))

"""#Median

"""

print("Median:\n",df.median(numeric_only=True))

"""#Minimum"""

print("Minimum:\n", df.min(numeric_only=True))

"""#Maximum

"""

print("Maximum:\n", df.max(numeric_only=True))

"""#Standard Deviation"""

print("Standard Deviation:\n", df.std(numeric_only=True))

"""#Bonus: Check Missing Values"""

print("Missing Values:\n", df.isnull().sum())

"""Result: No missing values in the Iris dataset.

#CLEANING
"""

df.head()

df .tail()

df .info()

df .columns

df .describe()

df['Species'].value_counts()

df.dropna(inplace=True)
df = df.dropna()

if 'Id' in df.columns:
    df = df.drop(columns=['Id'])

df.Species.value_counts(normalize= True)

df .info()

"""#Data Cleaning Summary

Loaded dataset → Imported the CSV file and checked shape, columns, and first few rows.

Checked missing values → No null values were found in any column.

Checked duplicates → No duplicate rows were found (but we would drop them if they existed).

Dropped unnecessary column → Removed the Id column since it does not add predictive value.

Renamed columns → Renamed feature columns to cleaner, lowercase names (sepal_length, petal_length, etc.) for easier handling.

Handled categorical target → Converted the Species column into a categorical type (and later encoded for modeling).

Reset dataset → Ensured the cleaned dataset is consistent, with no missing/duplicate records and only useful features retained.

✅Final cleaned dataset: 150 rows × 5 columns (4 numeric features + 1 categorical target species).

#EDA
"""

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Basic stats
print(df.describe())
print(df['Species'].value_counts())

# 2. Histograms (distribution of each numeric feature)
df.hist(bins=15, figsize=(10,8))
plt.suptitle("Feature distributions")
plt.show()

# 3. Boxplots by species (detect outliers / distribution differences)
numeric_cols = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
for c in numeric_cols:
    plt.figure(figsize=(6,4))
    sns.boxplot(x='Species', y=c, data=df)
    plt.title(f"{c} by Species")
    plt.show()

# 4. Correlation heatmap
plt.figure(figsize=(6,4))
corr = df[numeric_cols].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title("Correlation between numeric features")
plt.show()

# 5. Pairplot (relationship between features colored by species)
sns.pairplot(df, hue='Species')
plt.suptitle("Pairplot by Species")
plt.show()

# x- y = features
#hue always set as target column
#data= dataframe having data valuesView
#palette = color of the graph
#s=size
sns.scatterplot(x = "SepalLengthCm", y = "SepalWidthCm", hue = "Species", data = df, palette="Dark2", s=80)
plt.title("Sepal Length vs Sepal Width and Species")
plt.show()
sns.scatterplot(x = "PetalLengthCm", y = "PetalWidthCm", hue = "Species", data = df, palette="Dark2", s=80)
plt.title("Petal Length vs Petal Width and Species")
plt.show()

"""**Axes:**

X-axis: PetalLengthCm

Y-axis: PetalWidthCm

**Species aur Data Distribution**:

Iris-setosa (Green):

Sepal length: 4.5 cm  to 5.8 cm

Sepal width: 3.0 cm to 4.5 cm



Iris-versicolor (Orange):

Sepal length: 4.9 cm to 7.0 cm

Sepal width: 2.0 cm to 3.4 cm



Iris-virginica (Purple):

Sepal length: 4.9 cm to 7.9 cm

Sepal width: 2.2 cm to 3.8 cm


**Axes**:

X-axis: PetalLengthCm

Y-axis: PetalWidthCm

### **Species aur Data Distribution:**

Iris-setosa (Green):

Petal length: Lagbhag 1.0 cm to 2.0 cm

Petal width: Lagbhag 0.1 cm to 0.6 cm



Iris-versicolor (Orange):

Petal length: Lagbhag 3.0 cm to 5.0 cm

Petal width: Lagbhag 1.0 cm to 1.8 cm

Middle cluster

Iris-virginica (Purple):

Petal length: Lagbhag 4.5 cm to 7.0 cm

Petal width: Lagbhag 1.4 cm to 2.5 cm

###EDA Summary

Descriptive statistics → Checked mean, min, max, standard deviation of all numeric features.

Class distribution → Verified that all three species (setosa, versicolor, virginica) are equally represented (50 samples each).

Feature distributions → Plotted histograms for all features (sepal_length, sepal_width, petal_length, petal_width) to understand spread and variation.

Boxplots by species → Compared how each feature varies across the three species (e.g., petal length/width clearly separate species).

Correlation heatmap → Found strong positive correlation between petal length and petal width, weaker correlation for sepal features.

Pairplot (scatter plots) → Visualized relationships between all features. Showed clear clusters, with Iris-setosa easily separable, while versicolor and virginica overlap slightly.

✅ Key insight: Petal features (length & width) are the strongest indicators for distinguishing species, while sepal features are less discriminative
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

import matplotlib.pyplot as plt
import seaborn as sns

sns.catplot(x= "Species", y = "SepalLengthCm", data =df, kind = "box", aspect = 2)
plt.title("Boxplot for Species vs Sepal Length")
plt.show()

df.head()

df.describe()

df.info()

df.columns

df.duplicated().sum()

df.drop_duplicates(inplace = True)

plt.figure(figsize = (20,5))
sns.countplot(x='SepalLengthCm', data=df)
plt.xlabel('Sepal Length')
plt.ylabel('Count')
plt.title('Distribution of Sepal Length')
plt.show()

plt.figure(figsize = (20,5))
sns.countplot(x='SepalWidthCm', data=df)
plt.xlabel('Sepal Width')
plt.ylabel('Count')
plt.title('Distribution of Sepal Width')
plt.show()

plt.figure(figsize = (20,5))
sns.countplot(x='PetalLengthCm', data=df)
plt.xlabel('Petal Length')
plt.ylabel('Count')
plt.title('Distribution of Petal Length')
plt.show()

plt.figure(figsize = (20,5))
sns.countplot(x='PetalLengthCm', data=df)
plt.xlabel('Petal Length')
plt.ylabel('Count')
plt.title('Distribution of Petal Length')
plt.show()

df.drop(columns=['Species']).corr()

correlation_matrix = df.drop(columns=['Species']).corr()
sns.heatmap(correlation_matrix, annot=True, cmap= 'Pastel1')
plt.title('Correlation Matrix of Iris Dataset')
plt.show()

sns.pairplot(df, hue= 'Species', size = 2.5)

df.drop(columns=['Species']).corr()

df.head()

df['Species']

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

df['Species'] = le.fit_transform(df['Species'])
df['Species']

Y = df['Species']
X = df.drop(columns= ['Species'])


from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.80)
X_test.shape

X_test.head()

X_train.shape

"""##Logistic Regression"""

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

model.fit(X_train, Y_train)

y_pred = model.predict(X_test)
score = accuracy_score(Y_test, y_pred)
accuracy = score*100
print(accuracy)

y_pred

Y_test

from sklearn.metrics import confusion_matrix

# PRINT THE CONFUSION MATRIX
print("Confusion Matrix")
cm = confusion_matrix(Y_test, y_pred)
print(cm)

plt.figure(figsize = (6, 4))
sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', cbar = False, annot_kws = {'size' : 14})
plt.xlabel('Predicted Labels', fontsize = 14)
plt.ylabel('True Labels', fontsize = 14)
plt.title('Confusion Matrix', fontsize = 16)
plt.show()

from sklearn.metrics import classification_report

# Generate classification report
report = classification_report(Y_test, y_pred)
print(report)

# Extract coefficients from the trained model
coefficients = model.coef_

# Get feature names from the training data
feature_names = X_train.columns

# Create a DataFrame for the coefficients
coef_df = pd.DataFrame(coefficients, columns=feature_names, index=model.classes_)

# Plot heatmap
plt.figure(figsize=(8,6))
sns.heatmap(coef_df, annot=True, cmap="coolwarm", center=0, cbar_kws={'label': 'Coefficient Value'})
plt.title("Logistic Regression Coefficients Heatmap")
plt.xlabel("Features")
plt.ylabel("Classes")
plt.show()

"""##Decison Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier()
clf.fit(X_train, Y_train)

y_pred = clf.predict(X_test)
score = accuracy_score(Y_test, y_pred)
accuracy = score*100
print(accuracy)

from sklearn import tree
tree.plot_tree(clf)

from sklearn.metrics import confusion_matrix
y_pred = clf.predict(X_test)

# PRINT THE CONFUSION MATRIX
print("Confusion Matrix")
cm = confusion_matrix(Y_test, y_pred)
print(cm)

plt.figure(figsize = (6, 4))
sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', cbar = False, annot_kws = {'size' : 14})
plt.xlabel('Predicted Labels', fontsize = 14)
plt.ylabel('True Labels', fontsize = 14)
plt.title('Confusion Matrix', fontsize = 16)
plt.show()

from sklearn.metrics import classification_report

# Generate classification report
report = classification_report(Y_test, y_pred)
print(report)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Reds",
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix - Decision Tree")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""##GussianNB"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train,Y_train)

y_pred = nb.predict(X_test)
score = accuracy_score(Y_test, y_pred)
accuracy = score*100
print(accuracy)

from sklearn.metrics import confusion_matrix
y_pred = nb.predict(X_test)

# PRINT THE CONFUSION MATRIX
print("Confusion Matrix")
cm = confusion_matrix(Y_test, y_pred)
print(cm)

plt.figure(figsize = (6, 4))
sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', cbar = False, annot_kws = {'size' : 14})
plt.xlabel('Predicted Labels', fontsize = 14)
plt.ylabel('True Labels', fontsize = 14)
plt.title('Confusion Matrix', fontsize = 16)
plt.show()

plt.figure(figsize=(8,6))
sns.heatmap(coef_df, annot=True, cmap="coolwarm", center=0, cbar_kws={'label': 'Coefficient Value'})
plt.title("SVC (Linear Kernel) Coefficients Heatmap")
plt.xlabel("Features")
plt.ylabel("Classes")
plt.show()



"""svm suport vector machine
svc support vector classifier
svr support vector regressor

##Support Forest Classifier
"""

from sklearn.svm import SVC
sfc = SVC()
sfc.fit(X_train,Y_train)

y_pred = sfc.predict(X_test)
score = accuracy_score(Y_test, y_pred)
accuracy = score*100
print(accuracy)

from sklearn.metrics import confusion_matrix
y_pred = sfc.predict(X_test)

# PRINT THE CONFUSION MATRIX
print("Confusion Matrix")
cm = confusion_matrix(Y_test, y_pred)
print(cm)

plt.figure(figsize = (6, 4))
sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', cbar = False, annot_kws = {'size' : 14})
plt.xlabel('Predicted Labels', fontsize = 14)
plt.ylabel('True Labels', fontsize = 14)
plt.title('Confusion Matrix', fontsize = 16)
plt.show()

plt.figure(figsize=(8,6))
sns.heatmap(coef_df, annot=True, cmap="coolwarm", center=0, cbar_kws={'label': 'Coefficient Value'})
plt.title("SVC (Linear Kernel) Coefficients Heatmap")
plt.xlabel("Features")
plt.ylabel("Classes")
plt.show()

"""###RandomForestClassifier"""

from sklearn.ensemble import RandomForestClassifier
classifier= RandomForestClassifier(n_estimators= 10, criterion="entropy")
classifier.fit(X_train,Y_train)

y_pred = classifier.predict(X_test)
score = accuracy_score(Y_test, y_pred)
accuracy = score*100
print(accuracy)

from sklearn.metrics import confusion_matrix
y_pred = classifier.predict(X_test)

# PRINT THE CONFUSION MATRIX
print("Confusion Matrix")
cm = confusion_matrix(Y_test, y_pred)
print(cm)

#Get feature importances
importances = classifier.feature_importances_
feat_df = pd.DataFrame(importances.reshape(1, -1),
                       columns=X.columns)

# Plot as heatmap
plt.figure(figsize=(8,2))
sns.heatmap(feat_df, annot=True, cmap="YlOrRd", cbar_kws={'label': 'Importance'})
plt.title("Random Forest Feature Importances")
plt.ylabel("Random Forest")
plt.show()